{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07 -- More NN\n",
    "\n",
    "Note I have added the solution to the exercise at the bottom of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals for the lab\n",
    "- Repeat the logistic regression exercise but add tensorflow logging\n",
    "- Save the model weights\n",
    "- Add a hidden layer to the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The %run command executes a python file as if it was a cell in the notebook. \n",
    "%run plot_images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8VXP+x/HXt6SbwgjpohMRYaRpumAkIvkh5FIuIzIM\nlWjIlPudikSMGFOSMkrSA9UPY4wpMplJRpRrKVO/klCTUN/fH/t89lp7n30u+5y99trn9H4+Hh57\n7bXWXuub79nf/Vnfq/PeIyKyvasVdwJERAqBCkMREVQYiogAKgxFRAAVhiIigApDERFAhaGICKDC\nUEQEUGEoIgLADtmc3KRJE19UVBRRUgrP559/zrp161zc6cgn5XHNpzzOLKvCsKioiIULF1Y+VdVM\nx44d405C3imPaz7lcWZ6TBYRQYWhiAigwlBEBFBhKCICqDAUEQGybE2uDn75y18mt5cuXQrA4sWL\ngUQrmohIJooMRUSoQZFhnz59ADL2n/r6668BRYYihWbo0KEA3H///QDYMiTOBX2kt23blpe0KDIU\nEaEaR4b2C3LttdcCMGPGjDiTIzG78cYbAbjtttsAmDVrFgAnn3xybGmS8llEWLt2bQC2bt2a8j6f\nFBmKiFANI0P75bj++usBGDVqVMrxunXrljhXai6rD37ooYcAOO+88wBFhIXuzTffBIInPPuutmjR\nAoBnnnkm72lSZCgiQjWJDMMR3g033ADA3XffnXJOo0aNAJg7d25yn7Us77///lEnUbK0efNmAFat\nWgVAmzZtKnWde+65B4D169cDsMcee+QgdRK1sWPHAkGrsdURhluR802RoYgIBR4ZWv+iV155Jbnv\nrrvuSjlnv/32A+DVV18FoGXLlsljXbt2jTqJkiUbDXThhRcC8K9//QuAF198MXlOr169Kny9SZMm\nAbDnnnsC0K9fv5ykU3LP+hRCUCeYXmfYpUuXlNd8UmQoIoIKQxERoMAfk1966SUgczeJ1q1bA7Bs\n2bK8pkmyY48/1hn6vvvuA6Bt27YA3HLLLQDstdde5V7rp59+AoIO1gCrV68G4Pe//z2wfU7jX11Y\nB2sovZP1VVddlf+EFVNkKCJCgUaGzz77LABnnHFGiWM9evQAYM6cOXlNk1SORYQWAVoDx5QpU7K+\n1sqVK4HURrQdd9wRgBNPPLFK6ZToWWMJBBFhaQ0ocVBkKCJCgUWGNrTqjjvuSNnfvn375Pbs2bOB\neAZyS9nS6wfD2wcccAAQdJKujMmTJ5fYZ901jjzyyEpfV/Ij3KG6ECZmSKfIUESEAokMN2zYAAT1\nPtYRt3PnzkAQDQLssENBJFky+PTTT4GgfhBg1113BYKO882bN6/09Z977rkS+wYPHlzp60l+nH32\n2UDZdYZTp07Nf8LSKDIUESHmyNCG2915550AvPXWW0AQPTz99NNAEF2UZfny5UAwBRAURj3E9iRT\nC/G9994LVC0itIW9lixZAqTWPcU5sF/KZtN0LViwAMhcZ2hPf3G2IhtFhiIixBwZWn9Cm6C1Tp06\nAIwePRrIvICTRZPvvPMOAFdccQUQRJXhgfpPPvkkoAgxavPnzwfg9ttvL3GsopOsbtq0KbltEaD1\nLrDp2r7//nsAunXrljzX+h7aa9OmTYHUCTskHocffjgQRISZ6gxPP/10IPWJLi6KDEVEUGEoIgLE\n8JgcXsXu0ksvTTl28cUXA9C3b9+U/eHw2mavtorXdOEm+ltvvRWo/CzKUjEfffQREEykMGjQoOSx\nXXbZJeXcd999FwgefT/++GMANm7cmDznww8/LPN+r7/+enK7U6dOQNBAYxNB6DE5fldffTUQTNAQ\nnrG+EKuuFBmKiJDHyNB++ceNG5fcZxXkNm2P/aqnCw/hGj58eFRJlEp67LHHUt4fdthhyW0bQmdD\nLK1jdv369YFgKrbLL7+8xHWtgc0iwXPPPReACRMmlDjXKunVKT9+9j22htCyGlDCs1/HTZGhiAh5\njAyt3uC1115L7rN6nSFDhmT8jA3hyiYabNy4cXK7QYMGWadTsrfPPvsAMG/ePAAGDBhQ6rkHHngg\nEEzg0KdPn1LPDQ/DhGCtbOuCJYXFOlm//fbbQMmV78J1hlafWEgUGYqIkIfI0DrTWgfoMJuqvVWr\nVin7P/vsMyC7lc6sg/Zf/vKX5L5mzZpllVapnGHDhgHwwgsvAEFdMAStyXaO1Q/Xq1ev1OtZHtoE\nvjbJry0VIIWptE7WFhGeeeaZyXNHjhyZ59SVT5GhiAh5iAy//fZbANavX1/i2Jo1awCYO3cuEPyC\njB07FoB169aVe31bBsDWYa3IpA6SWwcffDAQDMuzyB6Cda2z6et57bXXAkFkYdfQpAyFrbQ6wkJY\n7KkiFBmKiKDCUEQEyMNjsq2H26tXLyCYoxCC4XLlqVUrKLP33ntvAB5++OGU60r8bJ0Te82VE044\nIafXk9xKn8m6tJXvwp2uC5EiQxER8tjpetKkSQBcdtllyX1PPPFEyjkrVqwASna27d+/f3L78ccf\njyiFUmhs9uN27drFnBJJZx2soeRM1ukNKNbButAbwBQZiogQwxReXbt2zbgNQSfb9MjQpmmS7cs5\n55wDQJMmTWJOiaSbNm1actue6EqrI7TvbyGsc1IWRYYiIhTIusnGWg0LvdVJZHtnE69A6Z2s7X2h\n1xUaRYYiIhRYZCgCcNBBBwFBvdTgwYPjTI5kYKtU1iSKDEVEUGQoBWjixIlxJ0G2Q4oMRURQYSgi\nAqgwFBEBVBiKiAAqDEVEABWGIiIAuGyGvjnn1gLLo0tOwWnlvd897kTkk/K45lMeZ5ZVYSgiUlPp\nMVlEBBWGIiJAxMPxnHO7Aa8Wv20KbAXWFr/v5L3/IaL7/gz4I9AO8MAF3vu3o7jX9i6uPC6+9w7A\nP4FPvfenRnWf7V2M3+MngBOBVd779lHcI+V++aozdM7dDGz03o9O2++K05GzaTCcc08BL3vvJzrn\ndgTqe++/ydX1JbN85nHxdYcB7YEGKgzzI8/f427AZuDRfBSGsTwmO+faOOeWFBda7wMtnXMbQsf7\nOuf+WLy9p3NuhnNuoXPubedcmXOHF0eFnb33EwG89z+oIMy/KPO4+DOtgOOACVH9G6RsUeex9/51\nYH1k/4A0cdYZHgCM8d63A1aVcd4DwEjvfUfgLBKPvzjnOjvnHslw/j7AWufcJOfcv5xzjzrnGuQ6\n8VIhUeUxwP3ANSSqQSQ+UeZxXsU5hdcn3vuFFTivB9A2NHX4rs65+t77BcCCDOfvAHQEBgPvAA+S\n+NLcUvUkS5YiyWPn3KnAF977Rc65HrlLrlRCVN/jvIuzMNwU2t4GhBdKqBfadmRXSbsSWGEZ5Jx7\nFriyKgmVSosqjw8HTnfOnVJ8ncbOuSe89xdUKbVSGVHlcd4VRNea4krXr51z+znnagGnhQ6/Agy0\nN865MitSvfcrgTXOuTbFu44FluQ4yZKlHOfxMO99C+99EXAe8L8qCOOXyzyOQ0EUhsWuBeYC80lE\nd2YgcIRzbrFzbgnwGyi3rmEw8Gfn3GLgIODu6JItWchlHkthylkeO+emAW8A7ZxzK51z/aNMuIbj\niYhQWJGhiEhsVBiKiKDCUEQEUGEoIgKoMBQRAbLsdN2kSRNfVFQUUVIKz+eff866detc+WfWHMrj\nmk95nFlWhWFRURELF1Zk5E3N0LFjx7iTkHfK45pPeZyZHpNFRFBhKCICqDAUEQFUGIqIACoMRUQA\nFYYiIkC8k7uW6osvvgDgmmuuAWDGjBnJY7VqJcpvmzH3p59+AmDQoEEAjBw5MnlunTp1ok+sZOXu\nuxOzqY0YMQKAU09NrON05JFHJs8JzYacolu3bgB06NAhyiRKjLZu3QoE32uAMWPGALBpU2Ie2cMP\nPxyAE044ASj97yVbigxFRCiQyHDdunUA3H777QA88khirscddkgk7+mnn06ee/rpp6d8dunSpQD0\n6JFYCmOnnXZKHrvtttsiSrFU1LJlywB48sknARg9OrHCpP2aP//88wDMnDkz+ZnSful33nlnIPj7\nADj55JMBqF+/fi6TLXlmUd9vf/tbACZPnlzuZ7777jsg9TtfFYoMRUQokMhwxYoVAIwdOxaAnj17\nAjB+/HgAWrVqVepn27ZtC8CQIUMA+Oc//xlZOiV7l156KQB/+9vfqnytb75JLH/dt2/f5L4BAwYA\ncN999wHQqFGjKt9HomfDAZcvXw7AJZdcAsD69YllknfZZZfkub/73e+A4Lv93HPPAXDLLYkFL0eN\nGpWTNCkyFBGhQCLDdBMnTgSgadOm5Z5rrU5z584FoGHDhpGlS7J3yimnALmJDDP505/+BAQ9Bx5+\n+OFI7iOVt2XLFiBoFQa4//77AVizZk3KuVb3H+5BYtG+tQFYZGj1z4oMRURyqCAiQ4sArZ7Aft1v\nvfXWcj/7xhtvAEHk8dRTT0WRRKmkWbNmZf2ZG2+8EQhaj9Ov9de//rXEZ957773sEyeR+uSTT4Cg\nPv/FF18s9Vz7rtu54bpfazW2emFjPQlyRZGhiAgqDEVEgAJ5TG7WrBkQNK9bB93hw4cDmTvUWkft\nCRMmAHDhhRcCcMYZZ0SbWMnKzTffDAQNKfb4Y3ltj8QVYV2wXnvttRLH5s2bB8D06dMB/R0UgrVr\n1wJlPx7b34N1l2rcuHGJc6yxZcOGDSn7b7rpppyk0ygyFBGhQCJDc9555wHBL4E1pd95553Jc+zX\n5uqrrwbg5ZdfBuChhx7KWzql4mxyBRs2Wbt2bQB23333Cl9j9uzZQNCNJjxcL31Y37HHHlvFFEuu\n2BPdwQcfXOLYfvvtB8DQoUNT3hvrfA3wwAMPZLz+z3/+85yk0ygyFBGhwCLDQw45BAiG31hT+mWX\nXZY858EHHwRg6tSpKa/pEzhIYalIB/rSWCd862IR1qRJEyCx4htowoZCcuihhwLZdXv66quvgNQ6\nX2sfMKeddhoQPGXkiiJDEREKLDI0NgDbhuQceOCByWM2/O6JJ54AoE+fPnlOnUTtv//9LxAMzF+w\nYEGp5x5zzDFA5nopqX4effRRIHPHepsI2NoQbKLnXFFkKCJCgUaGNuj+rLPOAlInabX+SP369ct/\nwiQvrF9aeKqu0lj/RanebCo2awMIa968ORD0FDjggAMiSYMiQxERCjQyXLVqFRBM9x9e2MmOSc1i\n9UFQ/uQONoUTQO/evSNLk0TH+gsPHDgQgJdeegmAzZs3lzjX2g46deoUaZoUGYqIoMJQRAQosMfk\nlStXAsFstxYWh5vZrSvFlClTADjnnHPymELJFes+Y2ukhB+NS1sdzx6J9Wgcv8WLFye3bQKNdDY/\nqa2J/eabbyaPXXfddUDJSTdatGgBQP/+/ZP72rdvX/UEV4AiQxERCiQy/PHHHwG4/PLLAfjZz34G\nBNNzhRtQbGjWcccdB8C2bduAYJIHKWwvvPACEHSs12qG1YNNn9W9e3cgeIqDksPljK1HZJMwfPzx\nx8ljGzduzPgZm4rvsMMOS+4rbQowWxmzXbt25f8DKkCRoYgIBRIZvvXWW0AwHZf9EoQjQtOlSxcg\nWOvk/PPPB2D+/PlA6gpcdevWjSjFUlE2ucLrr78OwEUXXQQEA/KzYdN0nX322SWO2UQNtoaGTRgs\nVWNPbfb/ddGiRRX+7KZNm7L+THiARXly3c1OkaGICDFHhraeqv3q2BA7azEuiw3DeuaZZwC48sor\nAbjrrruS59iU85IfVq8U/nW3OsFcrps8bdq05HZ6y7P9PXz22Wc5u9/27N577wVg0qRJKfu7du2a\n3LYeAbZ+8fvvv1/l+4Yne7V72YTO9erVA2Cvvfaq8n3CFBmKiBBzZGjrqq5evRoIWhiz0bNnTwDG\njRsHpE4KafWJ++67b5XSKZkNHjwYKHvJBe89UHrfwfTzKqKsc5cvXw4ES0fYE4Nk54cffgDg7rvv\nznjclnGAYOG2//znPxnP7dWrFwAjRoxI7tt7773LvL+1RAPstttuFUhx1SkyFBFBhaGICBDzY/Kc\nOXOAYK3UbFZMS3fEEUcAsMceeyT32RCvq666qtLXlZIee+wxIJiVuLxH4IqcY3NXVuTc8GOynWvd\nN2zo1v77719umqR05557LgDffPNNxuPh1evS2ffYvne2Al6hd3VTZCgiQsyR4dFHHw0Eq+FdcMEF\nQNCMn80via2JsmzZsuS+cCWs5I4NpbL1aMpinZ9bt24NBI0urVq1Sjmvc+fOVUqTNZykX1cqZ/r0\n6RU+1yZkGDZsGBDMUWhPfNWFIkMREWKODG1d1fHjxwNBNwhb6eyoo44q8Zn0rhpvvPFGynurx4Jg\n6Jfkl0UKEAyttLyOiiLC3Jo5cyaQOgN5mHWXAbjpppuAqkf3cVNkKCJCzJFh7dq1AbjkkksA6NCh\nAxAMqbJO2V9++WWJz1pdlE37ZUP59txzzwhTLGWxOt9BgwYl90UdEUo0bLirdb5OZ99dyP36xXGp\nGf8KEZEqKogpvEzHjh1TXqUwWf8x9d+suawOPtM0ejWVIkMREVQYiogAKgxFRAAVhiIigApDERFA\nhaGICKDCUEQEUGEoIgKAy2btCefcWmB5dMkpOK2895WfcbYaUh7XfMrjzLIqDEVEaio9JouIoMJQ\nRARQYSgiAkQ8a41zbjfg1eK3TYGtwNri952895knS6v6fa8GLgQ88C5wkfd+SxT32t7FkcfOuVbA\nE8AeJPL4D977cbm+jyRsL3mctwYU59zNwEbv/ei0/a44HdtydJ9WJDLuYGALMB14zns/ORfXl9Ll\nMY+bAXt47xc55xoD/wJ6ee+XlfNRqaKanMexPCY759o455Y4554C3gdaOuc2hI73dc79sXh7T+fc\nDOfcQufc2865LhW4RR2gHonItwFQcqpsiVSUeey9/9J7v6h4+1vgQ6B5dP8ayaSm5XGcdYYHAGO8\n9+2AVWWc9wAw0nvfETgLsP+5nZ1zj6Sf7L1fDowFvgD+A/yf9/4vuU68VEgkeRzmnNuHxFPAP3KT\nZMlSjcnjOGe6/sR7v7AC5/UA2trMu8Cuzrn63vsFwIL0k4vrN04CWgPfAs865/p675/OUbql4iLJ\nY1P8+PQsMNh7v7HKqZXKqDF5HGdhuCm0vQ1woff1QtuO7Cppjwc+8t6vA3DOPQccDqgwzL+o8hjn\n3I7ADGCC935WlVIpVVFj8rggutYUV7p+7ZzbzzlXCzgtdPgVYKC9cc61L+dyK4Cuzrn6xZW6xwIf\n5DrNkp1c5nFxvk4EFnnvH4gguVIJ1T2PC6IwLHYtMBeYD6wM7R8IHOGcW+ycWwL8BsqsM5wHzCLR\n+vQe8BPweMRpl4rJSR4D3YB+wHHOuUXF//WMOO1SMdU2jzU2WUSEwooMRURio8JQRAQVhiIigApD\nEREgy36GTZo08UVFRRElpfB8/vnnrFu3zpV/Zs2hPK75lMeZZVUYFhUVsXBhRTqb1wwdO3aMOwl5\npzyu+ZTHmekxWUQEFYYiIoAKQxERQIWhiAigwlBEBFBhKCICqDAUEQFUGIqIACoMRUSAeKf9z6k1\na9YA8Oijj5Y49t133wEwatSolP0jR44E4Jprrok4dSLbrx9+SMz0f8MNNyT3/eMfibWdXnvttZRz\nr7zySgBGjBiR3Lf77rtHnURAkaGICFCgkeGHH34IwD333APAlClTksf22WcfALp37w7A448nZvS3\nGbt//PHHCt/npptuAhQZxmHGjBkAnHHGGUCQfwCnnZZYOqNZs2Ypn5k6dSoADz/8cHLfSSedBEDD\nhg2jS6xUyvfffw/ARRddBMDTTwdrsll+h1bLA2Ds2LElrjNmzJiokphCkaGICAUWGX7wQWIRO6vL\nmzhxYolzLGq016ro0qVLla8h2bFoYfTo0UDJyADg+eefL/Ma/fr1S25bHdN9992XqyRKFVke3377\n7QBMnz4dgOOPPz55TteuXQGYM2cOAAsWJJZOPvLII4HUCPHoo48GoHfv3hGmWpGhiAhQIJGhRYQ9\neyZWAvziiy+yvkbnzp1L7GvUqBEAw4YNA6BDhw4pxxs0aJD1faRqtm7dCsDGjRtzcr0vv/wyJ9eR\n3LGI8M477wSCul+LAsNWr14NJCZgBRg/fjwAJ554YvIcq2s8+eSTAahVK5oYTpGhiAgqDEVEgAJ5\nTH7wwQeB0h+PW7Zsmdw+7rjjUo5dcMEFABx22GElPrfDDol/Xv369XOSTqk66wIzZMgQAC655BIg\nqCQPs0en5cuX5yVtUjXWkdoaxxo3bgwEXaIyscaVZ599FoADDzww5RWCx2TrApde3ZUrigxFRCiQ\nyHDmzJkp71u1agXAr371KwCGDh2aPJYpApTqp2/fvkDQxaJdu3YlzglHB2G77rprcjv8tyHxOuus\nswDYsmULEDzx2fc4E2vkbNOmTcr+c845J7k9e/ZsAObNmwcoMhQRiVRBRIbpBgwYAKQO7JaaxeoO\nM0WEV1xxBQBLly7N+Nlx48Yltzt16hRB6iQb06ZNA4I63l69egHBMLyyvPvuu0AQIZozzzwzuX3+\n+ecD8NVXX1U5rWVRZCgiQoFGhmeffTYQTO/z7bffljjniCOOAKBJkyb5S5hE5pVXXkluT548Gcg8\nVA9Sh+NJPKzzPMCkSZMA2GmnnYBgGr3atWuXe530iNDUrVs3uW2t0jZM06b32nHHHbNNdpkUGYqI\nEHNkuGLFCiBofTJ9+vQB4JNPPgFg8+bNJT7btm1bACZMmAAErZJSvaxfvx6A6667Lrnvm2++KfMz\n4fqkgw46CICbb74594mTUv35z39Obr/44osAnHrqqQC0aNEip/c65ZRTAHjqqaeAoNxIb4GuKkWG\nIiLEHBlaPySLDsy///3vcj9rLY02QatNAKs6xML297//HQhaHgcPHgykRoOl1RUaG60AFauXktxb\nuHBhiX3Vvc+nIkMREVQYiogAMTwm28BsyLzeAQSrYVkjSdiGDRuA4FH65ZdfBmD+/PlAUNkqhWXu\n3LlAkD8//fRTnMmRSrL5B637EwTd3GyW6qiE18mJgiJDERFiiAzvuOOO5Hb6Sna//vWvgaAi9tBD\nDy3xeau4PfbYY4HMHbKl8FjkXtrqhZl+9e3JwKZiM+GB/+EuORI968q2bt265L4TTjghL/du3bo1\nEF0jqSJDERFiiAytI3Umt9xyCwBFRUWlntOxY0cgWCPBJn60DpmqMyxMgwYNAoLuVOkdq3feeefk\n9sCBA4Gg21SdOnXykUSpgPQBEgCHHHJIpPecNWsWEEz7tssuu0RyH0WGIiIUyEQNNjGDtSJXRHq9\nQWnTPUlhsKn7S2tFDtclX3755XlJk+RGFJFheO1saxf4xS9+kfP7hCkyFBEhhsjwscceS25by6JN\nzJDNwk3vv/9+yvuo6hGkahYsWABA7969Adi0aVPK8ebNmwOKBiXB6iTDE2/Y30h4KYAoKDIUEUGF\noYgIEMNj8lFHHZXctsfibB6PP/jgg5RXU91nzKhJ3nvvveS2dYGyYZTGHn3mzJmTv4RJzkQ1NK5/\n//4ALFq0KLnv1VdfBYKZtKOiyFBEhDxGhjZ8Z//990/usxmLR44cWeZnP/roo+T2XXfdBQQDxq1D\nbq7XQ5DsLVu2DICjjz46uc/mqrQ5Cm3NC1vfZt99981jCqWqbBZrW5cEYPz48UAwIKIyw+WsAW3G\njBlAaplwzDHHVC6xWVJkKCJCHiJDiwB69OgBwLZt25LHbNC3vVbG8OHDgfwNFpfS/eEPfwBS6wct\nIrRX66CriLB6uvjii4HUdYmGDBkCBB3rbR3lsvLYuljZULvZs2cDcPzxxwPxdLVSZCgiQh4iw+7d\nuwPQoEEDADZu3Fil61nd4IABA4Cg9UniY7/y4bWP09k6uNdff31e0iTRuuyyy5LbS5YsAeCRRx4B\noEOHDgC0a9cOgJ49ewKwePHi5GesN8inn34KBJHgbbfdBkDDhg0jS3tpFBmKiJDH1uTvvvsOSG0l\nsiE3mdZFDgv/Co0YMQLI/dqsUnk2+Wp4Gq50NrWa6nZrhvCEu1ZXbEMubaotG4ppr2G2VIBFk926\ndYsusRWkyFBEhBhGoAwbNizjtlRfVh947733AnDSSSclj9kU/aNHj85/wiSvLOpPH21UXSgyFBFB\nhaGICFAgM11LzdC5c2cA1q5dG3NKRLKnyFBEBBWGIiKACkMREQBcNpM0OufWAsujS07BaeW9r/iS\nfTWA8rjmUx5nllVhKCJSU+kxWUQEFYYiIkDE/Qydc7sBrxa/bQpsBawTWifv/Q8R3Xcl8HXx/bZ4\n7ztHcR+JJ4+dc+2AKaFd+wLDvffjcn0vifV7fCIwBqgNjPfej4riPsn75avO0Dl3M7DRez86bb8r\nTse2jB+s3L1WAgd776vnIMlqKp95HLp2HWAV0MF7vzLX15dU+crj4nxdCnQHVgMLgT7e+2W5uH4m\nsTwmO+faOOeWOOeeAt4HWjrnNoSO93XO/bF4e0/n3Azn3ELn3NvOuS5xpFmyk8c8Pg74QAVh/kWc\nx11I5Oty7/0W4Bmgd1T/Foi3zvAAYIz3vh2JX/bSPACM9N53BM4C7H9uZ+fcI6V8xgN/dc6945wb\nkMtES1aizGPTF5iai8RKpUSVx82BL0LvVxbvi0ycY5M/8d4vrMB5PYC2tqAQsKtzrr73fgFQctbI\nhC7e+1XOuabAy865D7z383OQZslOlHmMc64e8D/A0CqnVCor0jzOpzgLw02h7W2AC72vF9p2ZFlJ\n671fVfy62jn3PNAJUGGYf5HlcbH/ARZ479dVMn1SdVHl8SqgZeh9C8qOPKusILrWFFe6fu2c2885\nVws4LXT4FWCgvXHOtS/rWs65nZxzOxVvNyRRp/Tv3KdaspHLPA7phx6RC0aO8/gtoJ1zrpVzri6J\nR+tZuU5zWEEUhsWuBeaSiODCleEDgSOcc4udc0uA30CZdQ17AfOcc+8CbwPPee9LX7ZN8ilXeYxz\nrhGJlsaZ0SZZspSTPPbe/whcAbwMLAEme++XRplwDccTEaGwIkMRkdioMBQRQYWhiAigwlBEBFBh\nKCICqDDgM4/mAAAAE0lEQVQUEQFUGIqIACoMRUQA+H9dH2le2RvH+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cc1032198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_batch, y_batch = data.train.next_batch(9)\n",
    "plot_images(x_batch, y_batch.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a net to estimate/predict digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_inputs = 28*28\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input placeholders for the data `x` and the expected (1hot) labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, (None, 28*28), name='x')\n",
    "    y = tf.placeholder(tf.float32, (None, 10), name='y')\n",
    "    ec = tf.argmax(y, 1, name='ec') #[e]xpected [c]lass label\n",
    "  \n",
    "    # When this node is run, it will save an image to a log file.\n",
    "    #  - I am not assigning a variable to the result;,\n",
    "    #    all of the summary nodes can be collected by inspecting the graph later on. \n",
    "    tf.summary.image(\"image\", tf.reshape(x, [-1, 28,28,1]), max_outputs=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorflow, you can create nodes in the graph whose purpose is to save information to log files. The log files can be inspected using a tool called [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard). I hope to be able to demonstrate it later on in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we save data to the log file, the names become more important. We can group related nodes together using a 'name_scope' in order to make the log files easier to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('output'):\n",
    "    b = tf.Variable(tf.zeros(num_outputs), name='b')\n",
    "    W = tf.Variable(tf.truncated_normal([num_inputs, num_outputs]), name='W')\n",
    "    a = tf.add(tf.matmul(x, W), b, name='a')\n",
    "    z = tf.nn.softmax(a, name='z')\n",
    "    pc = tf.argmax(z, 1, name='pc')  # [p]redicted [c]lass label\n",
    "    \n",
    "    # Create nodes that will save histograms to the log file\n",
    "    #  -- histograms are good summaries of the (large) amount of data in the weights. \n",
    "    #  -- The let you spot common issues with gradient descent (stalling, diverging)\n",
    "    tf.summary.histogram(\"weights\", W)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The net is now complete for doing _inference_ or _estimation_. That is, you could use it (if the weights were set). Right now the weights are randomly set, the results will be random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhGo0RQRiUCNpohIBGo0RUQi+H/cqWkOL/z6ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cce17bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "x_batch, y_batch = data.test.next_batch(9)\n",
    "predictions = sess.run(pc, {x:x_batch, y:y_batch})\n",
    "plot_images(x_batch, y_batch.argmax(1), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the net for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct = tf.equal(ec, pc, name='correct')  # for each sample, did we get it right? \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='acc')\n",
    "\n",
    "    # Create a node to save the accuracy to a log file, \n",
    "    # so that we can go back and see how it improves after training. \n",
    "    tf.summary.scalar('accuracy', accuracy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08969999849796295\n",
      "Random chance is around 0.10 (10%)\n"
     ]
    }
   ],
   "source": [
    "# Normally, we would need to break the test data up into mini-batches.\n",
    "# however, this set is small enough that we will send the entire \n",
    "# test set in as one large batch. \n",
    "print(\"Accuracy: {}\".format(sess.run(accuracy, {x:data.test.images, y:data.test.labels})))\n",
    "print(\"Random chance is around 0.10 (10%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the log/summary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, let's look at the log data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE:* All log files will accumulate in the folder unless you delete them, or switch to a different log folder. If you are running this many times and adjusting settings, it is a good idea to think about how to choose differently named log folders for output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./log/run0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect all of the 'summary' nodes from the graph and generate a single log entry from them. \n",
    "summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A utility to save summarys to the log directory. \n",
    "#  -- This will create a file, each time we add a summary to the writer it gets appended to a log file.\n",
    "summary_writer = tf.summary.FileWriter('./log/run0', graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, log =  sess.run([accuracy, summary],\n",
    "                     {x:data.test.images, y:data.test.labels})\n",
    "summary_writer.add_summary(log, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the net, we need to define an objective function to minimize. In this case we will use the cross-entropy loss because our output it a softmax classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy:\n",
      "\n",
      "Make sure the correct conda environment is active, then run:\n",
      "    tensorboard --logdir=/home/justin/cse627a/log \n",
      "and open\n",
      "    http://localhost:6006/\n",
      "using your web browser\n"
     ]
    }
   ],
   "source": [
    "from pipes import quote\n",
    "print(\"Acuracy:\".format(acc))\n",
    "print()\n",
    "print(\"Make sure the correct conda environment is active, then run:\")\n",
    "print(\"    tensorboard --logdir={} \".format(quote(os.path.abspath('./log'))))\n",
    "print(\"and open\")\n",
    "print(\"    http://localhost:6006/\")\n",
    "print(\"using your web browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the graph for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=a)\n",
    "    loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "\n",
    "    # And define a node to log it\n",
    "    tf.summary.scalar('loss', loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('solver'):\n",
    "    solver = tf.train.AdamOptimizer()\n",
    "    optimize = solver.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('./log/run1/', graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The solver has some parameters that need to be initializes\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/logreg.cpt\n",
      "No model to restore\n",
      "Epoch: 0001 cost= 4.720562264\n",
      "Epoch: 0002 cost= 1.371919554\n",
      "Epoch: 0003 cost= 0.944586730\n",
      "Epoch: 0004 cost= 0.760865335\n",
      "Epoch: 0005 cost= 0.652589689\n",
      "Epoch: 0006 cost= 0.581364032\n",
      "Epoch: 0007 cost= 0.530487438\n",
      "Epoch: 0008 cost= 0.491582816\n",
      "Epoch: 0009 cost= 0.462384792\n",
      "Epoch: 0010 cost= 0.438551794\n",
      "Epoch: 0011 cost= 0.419319306\n",
      "Epoch: 0012 cost= 0.403087353\n",
      "Epoch: 0013 cost= 0.389303462\n",
      "Epoch: 0014 cost= 0.377467859\n",
      "Epoch: 0015 cost= 0.367368911\n",
      "Epoch: 0016 cost= 0.357773887\n",
      "Epoch: 0017 cost= 0.349654566\n",
      "Epoch: 0018 cost= 0.342827139\n",
      "Epoch: 0019 cost= 0.335817871\n",
      "Epoch: 0020 cost= 0.329968826\n"
     ]
    }
   ],
   "source": [
    " # Training cycle\n",
    "batch_size=100\n",
    "training_epochs=20\n",
    "display_epoch=1\n",
    "\n",
    "try:\n",
    "    saver.restore(sess, './models/logreg.cpt')\n",
    "except:\n",
    "    print(\"No model to restore\")\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    total_batch = int(data.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(batch_size)\n",
    "       \n",
    "        _, loss_, summary_ = sess.run([optimize, loss, summary],\n",
    "                                    {x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        global_iteration =  epoch * total_batch + i\n",
    "        summary_writer.add_summary(summary_, global_iteration)\n",
    "        \n",
    "        avg_loss += loss_ / total_batch\n",
    "        \n",
    "    # Display logs per epoch step\n",
    "    if (epoch+1) % display_epoch == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_loss))\n",
    "    \n",
    "    saver.save(sess, './models/logreg.cpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Add a hidden layer (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back and add a hidden layer. In addition to adding a hidden layer, we will also periodically check our model with the validation set and log the data. This gives a way to determine how well our model will generalize. Adding validation results to the summaries will require a few changes in how the summaries are built.\n",
    "\n",
    "First, since we are adding a hidden layer, we will have another parameter to tune our nerual network. This is the number of nodes in the hidden layer. For now we will set this to 1000, but this could be adjusted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "hidden_layer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear the current graph so that we can build a new graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the input layer. This is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, (None, 28*28), name='x')\n",
    "    y = tf.placeholder(tf.float32, (None, 10), name='y')\n",
    "    ec = tf.argmax(y, 1, name='ec')\n",
    "  \n",
    "    tf.summary.image(\"image\", tf.reshape(x, [-1, 28,28,1]), max_outputs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build our hidden layer. This layer will take the input, multiply by the weight tensor, and add a bias. That is:\n",
    "$$ \\mathbf{h_1} = f(\\mathbf{W}\\mathbf{x} + \\mathbf{b}) $$\n",
    "where $\\mathbf{x}$ is the input tensor, $\\mathbf{W}$ is the weights, $\\mathbf{b}$ is the bias, and $f$ is our activation function. Note that we have $\\mathbf{x}\\mathbf{W}$ in the code because of the shape of the input.\n",
    "\n",
    "For the activation function, we will use a rectified linear unit (ReLU). ReLU is mathematically defined as:\n",
    "$$f(x)=max(0,x)$$\n",
    "ReLU has several advantages over other activation functions, including both efficient computation and efficient gradient propagation.\n",
    "\n",
    "For the output layer, we do the same as before but use the output of the hidden layer as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden_layer'):\n",
    "    b1 = tf.Variable(tf.zeros(hidden_layer_size), name='b1')\n",
    "    W1 = tf.Variable(tf.truncated_normal([num_inputs, hidden_layer_size]), name='W')\n",
    "    preactivations = tf.add(tf.matmul(x, W1), b1, name='preactivations')\n",
    "    activations = tf.nn.relu(preactivations, name='activations')\n",
    "    \n",
    "    # Hidden layer summaries\n",
    "    tf.summary.histogram(\"weights_hidden_layer\", W1)\n",
    "    tf.summary.histogram(\"biases_hidden_layer\", b1)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    b2 = tf.Variable(tf.zeros(num_outputs), name='b2')\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_layer_size, num_outputs]), name='W1')\n",
    "    logits = tf.add(tf.matmul(activations, W2), b2, name='logits')\n",
    "    \n",
    "    z = tf.nn.softmax(logits, name='z')\n",
    "    pc = tf.argmax(z, 1, name='pc')\n",
    "    \n",
    "    # output layer summaries\n",
    "    tf.summary.histogram(\"weights_output\", W2)\n",
    "    tf.summary.histogram(\"biases_output\", b2)\n",
    "    \n",
    "# Merge all the summaries we have made so far.\n",
    "network_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the nodes that calculate the loss and accuracy. Our solver is the same as before. Notice that we have two seperate summaries for the training and validation. This is because if we use the same summary, both training and validation data will be added to the same graph, which is undesirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "\n",
    "    # Create nodes to log training and validation log loss.\n",
    "    training_loss_summary = tf.summary.scalar('training_loss', loss)\n",
    "    validation_loss_summary = tf.summary.scalar('validation_loss', loss)\n",
    "    \n",
    "with tf.name_scope('solver'):\n",
    "    solver = tf.train.AdamOptimizer()\n",
    "    optimize = solver.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct = tf.equal(ec, pc, name='correct')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='acc')\n",
    "\n",
    "    # Create nodes to log training and validation accuracy.\n",
    "    training_accuracy_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "    validation_accuracy_summary = tf.summary.scalar(\"validation_accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the two seperate summaries. train_summary logs weight data, sample images, along with the accuracy and log loss. validation_summary just keeps track of the validation accuracy and log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_summary = tf.summary.merge([training_loss_summary, training_accuracy_summary, network_summary])\n",
    "validation_summary = tf.summary.merge([validation_loss_summary, validation_accuracy_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/logreg2.cpt\n",
      "No model to restore\n"
     ]
    }
   ],
   "source": [
    "# Training cycle\n",
    "batch_size=100\n",
    "training_epochs=20\n",
    "display_epoch=1 # also determines when to run the validation set.\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_writer = tf.summary.FileWriter('./log/run2/', graph=sess.graph)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "try:\n",
    "    saver.restore(sess, './models/logreg2.cpt')\n",
    "except:\n",
    "    print(\"No model to restore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the model. This is the same as before, except we use our new summary nodes. Note that this takes a while to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train loss= 18.8901 train acc= 0.7841 val loss= 6.2379 val acc= 0.8972\n",
      "Epoch: 0002 train loss= 4.8123 train acc= 0.9107 val loss= 3.8810 val acc= 0.9272\n",
      "Epoch: 0003 train loss= 2.9480 train acc= 0.9356 val loss= 3.2596 val acc= 0.9350\n",
      "Epoch: 0004 train loss= 1.9939 train acc= 0.9493 val loss= 2.9646 val acc= 0.9370\n",
      "Epoch: 0005 train loss= 1.3602 train acc= 0.9602 val loss= 2.4540 val acc= 0.9454\n",
      "Epoch: 0006 train loss= 0.9672 train acc= 0.9671 val loss= 2.2819 val acc= 0.9488\n",
      "Epoch: 0007 train loss= 0.6630 train acc= 0.9738 val loss= 2.1251 val acc= 0.9512\n",
      "Epoch: 0008 train loss= 0.4678 train acc= 0.9781 val loss= 2.0300 val acc= 0.9536\n",
      "Epoch: 0009 train loss= 0.3393 train acc= 0.9826 val loss= 2.0764 val acc= 0.9532\n",
      "Epoch: 0010 train loss= 0.2757 train acc= 0.9847 val loss= 1.9710 val acc= 0.9568\n",
      "Epoch: 0011 train loss= 0.2257 train acc= 0.9869 val loss= 1.8517 val acc= 0.9584\n",
      "Epoch: 0012 train loss= 0.1702 train acc= 0.9889 val loss= 1.8606 val acc= 0.9548\n",
      "Epoch: 0013 train loss= 0.1497 train acc= 0.9905 val loss= 1.7325 val acc= 0.9608\n",
      "Epoch: 0014 train loss= 0.1354 train acc= 0.9911 val loss= 1.8541 val acc= 0.9632\n",
      "Epoch: 0015 train loss= 0.1183 train acc= 0.9915 val loss= 1.7507 val acc= 0.9606\n",
      "Epoch: 0016 train loss= 0.1152 train acc= 0.9923 val loss= 1.8973 val acc= 0.9616\n",
      "Epoch: 0017 train loss= 0.1195 train acc= 0.9923 val loss= 1.6491 val acc= 0.9642\n",
      "Epoch: 0018 train loss= 0.0883 train acc= 0.9940 val loss= 1.8228 val acc= 0.9642\n",
      "Epoch: 0019 train loss= 0.1194 train acc= 0.9927 val loss= 1.8289 val acc= 0.9636\n",
      "Epoch: 0020 train loss= 0.0792 train acc= 0.9948 val loss= 1.6667 val acc= 0.9650\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    total_batch = int(data.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(batch_size)\n",
    "       \n",
    "        _, loss_, accuracy_, training_summary_ = sess.run(\n",
    "                        [optimize, loss, accuracy, train_summary],\n",
    "                        {x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        global_iteration =  epoch * total_batch + i\n",
    "        summary_writer.add_summary(training_summary_, global_iteration)\n",
    "        \n",
    "        avg_loss += loss_ / total_batch\n",
    "        avg_accuracy += accuracy_ / total_batch\n",
    "        \n",
    "    # Display logs per epoch step. Also runs the model through the validation data\n",
    "    if (epoch+1) % display_epoch == 0:\n",
    "        # Print training results\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"train loss=\", \"{:.4f}\".format(avg_loss),end=' ')\n",
    "        print(\"train acc=\", \"{:.4f}\".format(avg_accuracy),end=' ')\n",
    "        \n",
    "        # Also print and record validation results\n",
    "        xs, ys = data.validation.next_batch(data.validation.num_examples)\n",
    "        \n",
    "        # IMPORTANT: Do not run the optimize node here, as training the model with\n",
    "        # validation data would defeat the purpose of holding out data.\n",
    "        loss_, accuracy_, validation_summary_ = sess.run(\n",
    "                        [loss, accuracy, validation_summary],\n",
    "                        {x: xs, y: ys})\n",
    "        \n",
    "        global_iteration = epoch\n",
    "        summary_writer.add_summary(validation_summary_, global_iteration)\n",
    "        print('val loss= {:.4f}'.format(loss_),end=' ')\n",
    "        print('val acc= {:.4f}'.format(accuracy_))\n",
    "    \n",
    "    saver.save(sess, './models/logreg2.cpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
