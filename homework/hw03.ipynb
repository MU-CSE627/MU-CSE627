{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%pylab notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "* For math problems, you are _**encouraged**_ to use $\\LaTeX,$ however handwritten solutions are also accepted provided that they are __extremely__ tidy and thorough.  \n",
    "Just submit a scanned PDF in that case.\n",
    "* Please make sure you explain the rationale behind each step -- this is very important because:\n",
    "   1.  It shows me that you understood each step and that you are not (just) copying from a friend or a solution found online. \n",
    "   2.  It helps me understand your approach, I often see you using new approaches that are correct and also different that what I or the author came up with. \n",
    "* Pleas make sure <font color=red> all of your code fits on the printed pages</font>, this may require breaking long lines into several shorter ones. I must see your code in order to beleive it is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "4.14 (*) Show that for a linearly separable data set, the maximum likelihood solution\n",
    "for the logistic regression model is obtained by finding a vector $\\mathbf{w}$ whose decision\n",
    "boundary $\\mathbf{w}^T \\phi(\\mathbf{x}) = 0$ separates the classes and then taking the magnitude of $\\mathbf{w}$ to\n",
    "infinity.  \n",
    "> **NOTE:** is this a good or a bad thing about the maximum likelihood solution...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "4.18 (*) Using the result (4.91) for the derivatives of the softmax activation function,\n",
    "show that the gradients of the cross-entropy error (4.108) are given by (4.109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Demonstrate the [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) class from sklearn on a *two dimensonal* slice of either:\n",
    "1. The fisher iris data\n",
    "2. Data from one of the kaggle competitions\n",
    "\n",
    "You must:\n",
    "1. Separate your data into five different _test_ and _training_ sets, using [Stratified Kfold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) cross validation, making sure that you set the parameter to shuffle your data. \n",
    "1. For each of the 5 different folds/classifiers:\n",
    "    1. Show the the way the space is partitioned, e.g. Fig 2.28 or Fig 4.5. \n",
    "        1. Include a scatter plot of the training data, using colors to indicate the different target labels. \n",
    "        1. Include a scatter plot of the test data using a different marker (e.g. squares), also using different colors to indicate expected labels. \n",
    "    1. Use the [Classification Report](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) and the [Confusion Matrix](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) to present the quality of your classifiers.\n",
    "\n",
    "You must share code as well as figures. \n",
    "Comment on how well you think your classifier will work on a secret test set (e.g. Kaggle's test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **HINT:** I do not expect this to take a large amount of code; most of what I ask is available already in scipy / sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did this in about 30 minutes and 35 lines of code (other than what I have shared with you).  Here is the output _I_ produced for the first fold. I made use of the `plot_confusion_matrix` function that I have included in this notebook for you to use as well. \n",
    "\n",
    "### Fold # 1 (of 5)\n",
    "\n",
    "<img src=\"my-soln-plot-fold1.png\">\n",
    "```\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "     setosa       1.00      1.00      1.00        10\n",
    " versicolor       1.00      0.70      0.82        10\n",
    "  virginica       0.77      1.00      0.87        10\n",
    "\n",
    "avg / total       0.92      0.90      0.90        30\n",
    "```\n",
    "<img src=\"my-soln-cm-fold1.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris  # or use some other data, that is ok\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse627",
   "language": "python",
   "name": "cse627"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
